{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 14 : L1 and L2 Regularisation\n",
    "\n",
    "- Generalisation loosely means that the model actually learns the meaning of the data compared to the case of overfitting where it memorises the data. \n",
    "- **Regularisation methods** are those which reduce generalisation error. \n",
    "-  L1 and L2 regularization are used to calculate a number(**penalty**) added to the loss value to penalize the model for large \n",
    "weights and biases. \n",
    "- Large weights might indicate that a neuron is attempting to memorize a data element.\n",
    " - Generally, it is believed that it would be better to have many neurons contributing to a model’s output, rather than a select few. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Pass\n",
    "- L1 regularization’s penalty is the sum of all the absolute values for the weights and biases.This is a linear penalty as regularization loss returned by this function is directly proportional to parameter values. \n",
    "- L2 regularization’s penalty is the sum of the squared weights and biases. This non-linear approach penalizes larger weights and biases more than smaller ones because of the square function used to calculate the result.\n",
    "- In other words, L2 regularization is commonly used as it does not affect small parameter values substantially and does not allow the model to grow weights too large by heavily penalizing relatively big values. \n",
    "- L1 regularization, because of its linear nature, penalizes small weights more than L2 regularization, causing the model to start \n",
    "being invariant to small inputs and variant only to the bigger ones. That’s why L1 regularization \n",
    "is rarely used alone and usually combined with L2 regularization if it’s even used at all.\n",
    "- Regularization functions of this type drive the sum of weights and the sum of parameters towards 0​, which can also help in cases of exploding gradients (model instability, which might cause weights to become very large values). \n",
    "- Beyond this, we also want to dictate how much of an impact we want this regularization penalty to carry. We use a value referred to as lambda in this equation — where a higher value means a more significant penalty. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**L1 weight and bias regularisation :** <br>\n",
    "$$L_{1w} = \\lambda \\sum_{m} |w_m|$$\n",
    "$$L_{1b} = \\lambda \\sum_{n} |b_n|$$ \n",
    "\n",
    "**L2 weight and bias regularisation :** <br>\n",
    "$$L_{2w} = \\lambda \\sum_{m} w_{m}^2$$\n",
    "$$L_{2b} = \\lambda \\sum_{n} b_{n}^2$$ \n",
    "\n",
    "**Overall Loss:**<br>\n",
    "$$Loss = DataLoss + L_{1w} + L_{1b} + L_{2w} + L_{2b} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the modifications to the code,we'll start with the dense layer class and set the value of lamda nce these can be set separately for every layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# Dense layer \n",
    "class Layer_Dense: \n",
    " \n",
    "    # Layer initialization \n",
    "    def __init__(self, n_inputs, n_neurons,\n",
    "                weight_regularizer_l1=0, weight_regularizer_l2=0, \n",
    "                bias_regularizer_l1=0, bias_regularizer_l2=0): \n",
    "        \n",
    "        # Initialize weights and biases \n",
    "        self.weights = 0.01 * np.random.randn(n_inputs, n_neurons) \n",
    "        self.biases = np.zeros((1, n_neurons)) \n",
    "        # set regularisation strength\n",
    "        self.weight_regularizer_l1 = weight_regularizer_l1\n",
    "        self.bias_regularizer_l1 = bias_regularizer_l1\n",
    "        self.weight_regularizer_l2 = weight_regularizer_l2\n",
    "        self.bias_regularizer_l1 = bias_regularizer_l2\n",
    "        \n",
    " \n",
    "    # Forward pass \n",
    "    def forward(self, inputs): \n",
    "        # Remember input values \n",
    "        self.inputs = inputs \n",
    "        # Calculate output values from inputs, weights and biases \n",
    "        self.output = np.dot(inputs, self.weights) + self.biases \n",
    " \n",
    "    # Backward pass \n",
    "    def backward(self, dvalues): \n",
    "        # Gradients on parameters \n",
    "        self.dweights = np.dot(self.inputs.T, dvalues) \n",
    "        self.dbiases = np.sum(dvalues, axis=0, keepdims=True) \n",
    "        # Gradient on values \n",
    "        self.dinputs = np.dot(dvalues, self.weights.T) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we update our loss class to include the additional penalty if we choose to set the lambda hyperparameter for any of the regularizers in the layer’s initialization. We will implement this code into the Loss​ class as it is common for the hidden layers. What’s more, the regularization calculation is the same, regardless of the type of loss used. It’s only a penalty that is summed with the data loss value resulting in a final, overall loss value. For this reason, we’re going to add a new method to a general loss \n",
    "class, which is inherited by all of our specific loss functions (such as our existing Loss_CategoricalCrossentropy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common loss class \n",
    "class Loss: \n",
    " \n",
    "    # Calculates the data and regularization losses \n",
    "    # given model output and ground truth values \n",
    "\n",
    "    # Regularization loss calculation \n",
    "    def regularization_loss(self, layer): \n",
    " \n",
    "        # 0 by default \n",
    "        regularization_loss = 0 \n",
    " \n",
    "        # L1 regularization - weights \n",
    "        # calculate only when factor greater than 0 \n",
    "        if layer.weight_regularizer_l1 > 0: \n",
    "            regularization_loss += layer.weight_regularizer_l1*np.sum(np.abs(layer.weights)) \n",
    " \n",
    "        # L2 regularization - weights \n",
    "        if layer.weight_regularizer_l2 > 0: \n",
    "            regularization_loss += layer.weight_regularizer_l2*np.sum(layer.weights*layer.weights) \n",
    " \n",
    "        # L1 regularization - biases \n",
    "        # calculate only when factor greater than 0 \n",
    "        if layer.bias_regularizer_l1 > 0: \n",
    "            regularization_loss += layer.bias_regularizer_l1*np.sum(np.abs(layer.biases)) \n",
    " \n",
    "        # L2 regularization - biases \n",
    "        if layer.bias_regularizer_l2 > 0: \n",
    "            regularization_loss += layer.bias_regularizer_l2*np.sum(layer.biases*layer.biases) \n",
    " \n",
    "        return regularization_loss\n",
    "\n",
    "    def calculate(self, output, y): \n",
    " \n",
    "        # Calculate sample losses \n",
    "        sample_losses = self.forward(output, y) \n",
    " \n",
    "        # Calculate mean loss \n",
    "        data_loss = np.mean(sample_losses)\n",
    " \n",
    "        # Return loss \n",
    "        return data_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we’ll calculate the regularization loss and add it to our calculated loss in the training loop: \n",
    "```\n",
    "    # Calculate loss from output of activation2 so softmax activation \n",
    "    data_loss = loss_function.forward(activation2.output, y) \n",
    " \n",
    "    # Calculate regularization penalty \n",
    "    regularization_loss = loss_function.regularization_loss(dense1) + loss_function.regularization_loss(dense2) \n",
    " \n",
    "    # Calculate overall loss \n",
    "    loss = data_loss + regularization_loss\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created a new regularization_loss variable and added all layer’s regularization losses to it. This completes the forward pass for regularization, but this also means our overall loss has changed since part of the calculation can include regularization, which must be accounted for in the backpropagation of the gradients. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ther derivatives of L1 and L2 regularisation's are:\n",
    "$$\n",
    "\\frac{\\partial L_{1w}}{\\partial w_m} =\n",
    "\\begin{cases} \n",
    "1 & \\text{if } w_m > 0, \\\\\n",
    "-1 & \\text{if } w_m < 0.\n",
    "\\end{cases}\n",
    "$$\n",
    "$$\\frac{\\partial L_{2w}}{\\partial w_m} = 2 \\lambda w_m$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, -1]\n"
     ]
    }
   ],
   "source": [
    "weights = [0.2,0.8,-0.5] # weights of one neuron \n",
    "dL1 = [] # array of partial derivatives\n",
    "for w in weights:\n",
    "    if w >=0 :\n",
    "        dL1.append(1)\n",
    "    else:\n",
    "        dL1.append(-1)\n",
    "\n",
    "print(dL1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1. -1.  1.]\n",
      " [ 1. -1.  1. -1.]\n",
      " [-1. -1.  1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "weights =  np.array([[0.2, 0.8, -0.5, 1], \n",
    "                    [0.5, -0.91, 0.26, -0.5], \n",
    "                    [-0.26, -0.27, 0.17, 0.87]])\n",
    "\n",
    "dL1 = weights.copy()\n",
    "dL1 = np.where(dL1 >= 0,1.,-1.)\n",
    "print(dL1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now update the dense layer class with this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# Dense layer \n",
    "class Layer_Dense: \n",
    " \n",
    "    # Layer initialization \n",
    "    def __init__(self, n_inputs, n_neurons,\n",
    "                weight_regularizer_l1=0, weight_regularizer_l2=0, \n",
    "                bias_regularizer_l1=0, bias_regularizer_l2=0): \n",
    "        \n",
    "        # Initialize weights and biases \n",
    "        self.weights = 0.01 * np.random.randn(n_inputs, n_neurons) \n",
    "        self.biases = np.zeros((1, n_neurons)) \n",
    "        # set regularisation strength\n",
    "        self.weight_regularizer_l1 = weight_regularizer_l1\n",
    "        self.bias_regularizer_l1 = bias_regularizer_l1\n",
    "        self.weight_regularizer_l2 = weight_regularizer_l2\n",
    "        self.bias_regularizer_l1 = bias_regularizer_l2\n",
    "        \n",
    " \n",
    "    # Forward pass \n",
    "    def forward(self, inputs): \n",
    "        # Remember input values \n",
    "        self.inputs = inputs \n",
    "        # Calculate output values from inputs, weights and biases \n",
    "        self.output = np.dot(inputs, self.weights) + self.biases \n",
    " \n",
    "    # Backward pass \n",
    "    def backward(self, dvalues): \n",
    "        # Gradients on parameters \n",
    "        self.dweights = np.dot(self.inputs.T, dvalues) \n",
    "        self.dbiases = np.sum(dvalues, axis=0, keepdims=True) \n",
    "\n",
    "        # Gradients on regularization \n",
    "        # L1 on weights \n",
    "        if self.weight_regularizer_l1 > 0: \n",
    "            dL1 = self.weights.copy() \n",
    "            dL1 = np.where(dL1 >= 0. , 1. , -1.)\n",
    "            self.dweights += self.weight_regularizer_l1 * dL1 \n",
    "        \n",
    "        # L2 on weights \n",
    "        if self.weight_regularizer_l2 > 0: \n",
    "            self.dweights += 2 * self.weight_regularizer_l2*self.weights\n",
    "         \n",
    "        # L1 on biases \n",
    "        if self.bias_regularizer_l1 > 0: \n",
    "            dL1 = np.ones_like(self.biases) \n",
    "            dL1[self.biases < 0] = -1 \n",
    "            self.dbiases += self.bias_regularizer_l1 * dL1 \n",
    "\n",
    "        # L2 on biases \n",
    "        if self.bias_regularizer_l2 > 0: \n",
    "            self.dbiases += 2 * self.bias_regularizer_l2*self.biases \n",
    " \n",
    "        # Gradient on values \n",
    "        self.dinputs = np.dot(dvalues, self.weights.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can add weight and bias regularizer parameters when defining a layer:\n",
    "```\n",
    "# Create Dense layer with 2 input features and 3 output values \n",
    "dense1 = Layer_Dense(2, 64, weight_regularizer_l2​=5e-4, \n",
    "                            bias_regularizer_l2​=5e-4) \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We usually add regularization terms to the hidden layers only. Even if we are calling the \n",
    "regularization method on the output layer as well, it won’t modify gradients if we do not set the \n",
    "lambda hyperparameters to values other than 0​. <br>\n",
    "I have done the updates in the full modal code file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
