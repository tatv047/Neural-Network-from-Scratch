{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing with Out-of-Sample Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overfitting** is effectively just memorizing the data without any understanding of it. An overfit model will do very well predicting the data that it has already seen, but often significantly worse on unseen data. <br><br>\n",
    "![](img1.png) <br><br>\n",
    "- The left image shows an example of generalization. In this example, the model learned to separate red and blue data points, even if some of them will be predicted incorrectly. One reason for this might be the data that contains some “confusing” samples. When you look at the image, you can see that, for example, some of these blue dots might not be there, which would raise the data quality and make it easier to fit. A good dataset is one of the biggest challenges with neural networks.\n",
    "- The image on the right shows the model that memorized the data, fitting them perfectly and ruining generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traing and Testing Data\n",
    "\n",
    "Without knowing if a model overfits the training data, we cannot trust the model’s results. For this reason, it’s essential to have both *training* and *testing* purposes.  <br>\n",
    "Training data as separate sets for different data should only be used to train a model. The testing, or out-of-sample data, should only be used to validate a model’s performance after training (we are using the testing data during training later in this chapter for demonstration purposes only). The idea is that some data are reserved and withheld from the training data for testing the model’s performance. <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Cautionary Notes* <br><br>\n",
    "- In many cases, one can take a random sampling of available data to train with and make the remaining data the testing dataset. You still need to be very careful about information leaking through. One common area where this can be problematic is in time-series data. Consider a scenario where you have data from sensors collected every second. You might have millions of observations collected, and randomly selecting your data for the testing data might result in samples in your testingdataset that are only a second in time apart from your trainingdata, thus are very similar. This means overfitting can spill into your testing data, and the model can achieve good results on both the training and the testing data, which won’t mean it generalized well. \n",
    "- Randomly allocating time-series data as testing data may be very similar to training data. Both datasets must differ enough to prove the model’s ability to generalize. In time-series data, a better approach is to take multiple slices of your data, entire blocks of time, and reserve those for testing. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case, we can use our data-generating function to create new data that will serve as out-of-sample/testing data. Given what was just said about overfitting, it may look wrong to only generate more data, as the testing data could look similar to the training data. Intuition and experience are both important to spot potential issues with out-of-sample data. By looking at the image representation of the data, we can see that another set of data generated by the same function will be adequate. This is just about as safe as it gets for out-of-sample data as the classes are partially mixing at the edges (also, we’re quite literally using the “underlying function” to make more data). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these data, we evaluate the model’s performance by doing a forward pass and calculating \n",
    "loss and accuracy the same as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, acc: 0.360, loss: 1.099, lr: 0.05\n",
      "epoch: 100, acc: 0.670, loss: 0.705, lr: 0.04999752512250644\n",
      "epoch: 200, acc: 0.797, loss: 0.522, lr: 0.04999502549496326\n",
      "epoch: 300, acc: 0.847, loss: 0.430, lr: 0.049992526117345455\n",
      "epoch: 400, acc: 0.887, loss: 0.344, lr: 0.04999002698961558\n",
      "epoch: 500, acc: 0.910, loss: 0.303, lr: 0.049987528111736124\n",
      "epoch: 600, acc: 0.907, loss: 0.276, lr: 0.049985029483669646\n",
      "epoch: 700, acc: 0.917, loss: 0.252, lr: 0.049982531105378675\n",
      "epoch: 800, acc: 0.920, loss: 0.245, lr: 0.04998003297682575\n",
      "epoch: 900, acc: 0.930, loss: 0.228, lr: 0.049977535097973466\n",
      "epoch: 1000, acc: 0.940, loss: 0.217, lr: 0.049975037468784345\n",
      "epoch: 1100, acc: 0.937, loss: 0.205, lr: 0.049972540089220974\n",
      "epoch: 1200, acc: 0.947, loss: 0.192, lr: 0.04997004295924593\n",
      "epoch: 1300, acc: 0.947, loss: 0.184, lr: 0.04996754607882181\n",
      "epoch: 1400, acc: 0.943, loss: 0.183, lr: 0.049965049447911185\n",
      "epoch: 1500, acc: 0.943, loss: 0.189, lr: 0.04996255306647668\n",
      "epoch: 1600, acc: 0.943, loss: 0.165, lr: 0.049960056934480884\n",
      "epoch: 1700, acc: 0.943, loss: 0.161, lr: 0.04995756105188642\n",
      "epoch: 1800, acc: 0.943, loss: 0.158, lr: 0.049955065418655915\n",
      "epoch: 1900, acc: 0.943, loss: 0.155, lr: 0.04995257003475201\n",
      "epoch: 2000, acc: 0.947, loss: 0.151, lr: 0.04995007490013731\n",
      "epoch: 2100, acc: 0.943, loss: 0.148, lr: 0.0499475800147745\n",
      "epoch: 2200, acc: 0.953, loss: 0.145, lr: 0.0499450853786262\n",
      "epoch: 2300, acc: 0.957, loss: 0.142, lr: 0.0499425909916551\n",
      "epoch: 2400, acc: 0.957, loss: 0.138, lr: 0.04994009685382384\n",
      "epoch: 2500, acc: 0.957, loss: 0.135, lr: 0.04993760296509512\n",
      "epoch: 2600, acc: 0.960, loss: 0.132, lr: 0.049935109325431604\n",
      "epoch: 2700, acc: 0.957, loss: 0.130, lr: 0.049932615934796004\n",
      "epoch: 2800, acc: 0.937, loss: 0.159, lr: 0.04993012279315098\n",
      "epoch: 2900, acc: 0.960, loss: 0.125, lr: 0.049927629900459285\n",
      "epoch: 3000, acc: 0.960, loss: 0.123, lr: 0.049925137256683606\n",
      "epoch: 3100, acc: 0.960, loss: 0.121, lr: 0.04992264486178666\n",
      "epoch: 3200, acc: 0.960, loss: 0.119, lr: 0.04992015271573119\n",
      "epoch: 3300, acc: 0.960, loss: 0.117, lr: 0.04991766081847992\n",
      "epoch: 3400, acc: 0.960, loss: 0.115, lr: 0.049915169169995596\n",
      "epoch: 3500, acc: 0.950, loss: 0.131, lr: 0.049912677770240964\n",
      "epoch: 3600, acc: 0.957, loss: 0.118, lr: 0.049910186619178794\n",
      "epoch: 3700, acc: 0.960, loss: 0.113, lr: 0.04990769571677183\n",
      "epoch: 3800, acc: 0.960, loss: 0.111, lr: 0.04990520506298287\n",
      "epoch: 3900, acc: 0.960, loss: 0.110, lr: 0.04990271465777467\n",
      "epoch: 4000, acc: 0.960, loss: 0.109, lr: 0.049900224501110035\n",
      "epoch: 4100, acc: 0.960, loss: 0.107, lr: 0.04989773459295174\n",
      "epoch: 4200, acc: 0.960, loss: 0.106, lr: 0.04989524493326262\n",
      "epoch: 4300, acc: 0.960, loss: 0.104, lr: 0.04989275552200545\n",
      "epoch: 4400, acc: 0.960, loss: 0.103, lr: 0.04989026635914307\n",
      "epoch: 4500, acc: 0.960, loss: 0.102, lr: 0.04988777744463829\n",
      "epoch: 4600, acc: 0.960, loss: 0.101, lr: 0.049885288778453954\n",
      "epoch: 4700, acc: 0.960, loss: 0.100, lr: 0.049882800360552884\n",
      "epoch: 4800, acc: 0.960, loss: 0.099, lr: 0.04988031219089794\n",
      "epoch: 4900, acc: 0.960, loss: 0.098, lr: 0.049877824269451976\n",
      "epoch: 5000, acc: 0.960, loss: 0.098, lr: 0.04987533659617785\n",
      "epoch: 5100, acc: 0.967, loss: 0.107, lr: 0.04987284917103844\n",
      "epoch: 5200, acc: 0.960, loss: 0.097, lr: 0.04987036199399661\n",
      "epoch: 5300, acc: 0.960, loss: 0.096, lr: 0.04986787506501525\n",
      "epoch: 5400, acc: 0.960, loss: 0.095, lr: 0.04986538838405724\n",
      "epoch: 5500, acc: 0.960, loss: 0.094, lr: 0.049862901951085496\n",
      "epoch: 5600, acc: 0.960, loss: 0.094, lr: 0.049860415766062906\n",
      "epoch: 5700, acc: 0.960, loss: 0.093, lr: 0.0498579298289524\n",
      "epoch: 5800, acc: 0.960, loss: 0.092, lr: 0.04985544413971689\n",
      "epoch: 5900, acc: 0.960, loss: 0.092, lr: 0.049852958698319315\n",
      "epoch: 6000, acc: 0.960, loss: 0.091, lr: 0.04985047350472258\n",
      "epoch: 6100, acc: 0.960, loss: 0.090, lr: 0.04984798855888967\n",
      "epoch: 6200, acc: 0.960, loss: 0.089, lr: 0.049845503860783506\n",
      "epoch: 6300, acc: 0.960, loss: 0.089, lr: 0.049843019410367055\n",
      "epoch: 6400, acc: 0.960, loss: 0.088, lr: 0.04984053520760327\n",
      "epoch: 6500, acc: 0.953, loss: 0.126, lr: 0.049838051252455155\n",
      "epoch: 6600, acc: 0.960, loss: 0.090, lr: 0.049835567544885655\n",
      "epoch: 6700, acc: 0.960, loss: 0.088, lr: 0.04983308408485778\n",
      "epoch: 6800, acc: 0.960, loss: 0.088, lr: 0.0498306008723345\n",
      "epoch: 6900, acc: 0.960, loss: 0.087, lr: 0.04982811790727884\n",
      "epoch: 7000, acc: 0.960, loss: 0.086, lr: 0.04982563518965381\n",
      "epoch: 7100, acc: 0.960, loss: 0.086, lr: 0.049823152719422406\n",
      "epoch: 7200, acc: 0.960, loss: 0.085, lr: 0.049820670496547675\n",
      "epoch: 7300, acc: 0.960, loss: 0.085, lr: 0.04981818852099264\n",
      "epoch: 7400, acc: 0.960, loss: 0.084, lr: 0.049815706792720335\n",
      "epoch: 7500, acc: 0.960, loss: 0.083, lr: 0.0498132253116938\n",
      "epoch: 7600, acc: 0.960, loss: 0.083, lr: 0.04981074407787611\n",
      "epoch: 7700, acc: 0.960, loss: 0.082, lr: 0.049808263091230306\n",
      "epoch: 7800, acc: 0.960, loss: 0.082, lr: 0.04980578235171948\n",
      "epoch: 7900, acc: 0.963, loss: 0.081, lr: 0.04980330185930667\n",
      "epoch: 8000, acc: 0.963, loss: 0.081, lr: 0.04980082161395499\n",
      "epoch: 8100, acc: 0.963, loss: 0.080, lr: 0.04979834161562752\n",
      "epoch: 8200, acc: 0.963, loss: 0.084, lr: 0.04979586186428736\n",
      "epoch: 8300, acc: 0.963, loss: 0.080, lr: 0.04979338235989761\n",
      "epoch: 8400, acc: 0.963, loss: 0.079, lr: 0.04979090310242139\n",
      "epoch: 8500, acc: 0.963, loss: 0.079, lr: 0.049788424091821805\n",
      "epoch: 8600, acc: 0.963, loss: 0.078, lr: 0.049785945328062006\n",
      "epoch: 8700, acc: 0.963, loss: 0.078, lr: 0.0497834668111051\n",
      "epoch: 8800, acc: 0.963, loss: 0.077, lr: 0.049780988540914256\n",
      "epoch: 8900, acc: 0.963, loss: 0.077, lr: 0.0497785105174526\n",
      "epoch: 9000, acc: 0.963, loss: 0.076, lr: 0.04977603274068329\n",
      "epoch: 9100, acc: 0.963, loss: 0.076, lr: 0.04977355521056952\n",
      "epoch: 9200, acc: 0.963, loss: 0.075, lr: 0.049771077927074414\n",
      "epoch: 9300, acc: 0.963, loss: 0.075, lr: 0.0497686008901612\n",
      "epoch: 9400, acc: 0.707, loss: 1.982, lr: 0.04976612409979302\n",
      "epoch: 9500, acc: 0.963, loss: 0.079, lr: 0.0497636475559331\n",
      "epoch: 9600, acc: 0.963, loss: 0.076, lr: 0.049761171258544616\n",
      "epoch: 9700, acc: 0.963, loss: 0.076, lr: 0.0497586952075908\n",
      "epoch: 9800, acc: 0.963, loss: 0.075, lr: 0.04975621940303483\n",
      "epoch: 9900, acc: 0.963, loss: 0.074, lr: 0.049753743844839965\n",
      "epoch: 10000, acc: 0.967, loss: 0.074, lr: 0.04975126853296942\n",
      "validation, acc: 0.797, loss: 0.921\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import nnfs \n",
    "from nnfs.datasets import spiral_data \n",
    " \n",
    "nnfs.init() \n",
    " \n",
    " \n",
    "# Dense layer \n",
    "class Layer_Dense: \n",
    " \n",
    "    # Layer initialization \n",
    "    def __init__(self, n_inputs, n_neurons): \n",
    "        # Initialize weights and biases \n",
    "        self.weights = 0.01 * np.random.randn(n_inputs, n_neurons) \n",
    "        self.biases = np.zeros((1, n_neurons)) \n",
    " \n",
    "    # Forward pass \n",
    "    def forward(self, inputs): \n",
    "        # Remember input values \n",
    "        self.inputs = inputs \n",
    "        # Calculate output values from inputs, weights and biases \n",
    "        self.output = np.dot(inputs, self.weights) + self.biases \n",
    " \n",
    "    # Backward pass \n",
    "    def backward(self, dvalues): \n",
    "        # Gradients on parameters \n",
    "        self.dweights = np.dot(self.inputs.T, dvalues) \n",
    "        self.dbiases = np.sum(dvalues, axis=0, keepdims=True) \n",
    "        # Gradient on values \n",
    "        self.dinputs = np.dot(dvalues, self.weights.T) \n",
    " \n",
    " \n",
    "# ReLU activation \n",
    "class Activation_ReLU: \n",
    " \n",
    "    # Forward pass \n",
    "    def forward(self, inputs): \n",
    "          # Remember input values \n",
    "        self.inputs = inputs \n",
    "        # Calculate output values from inputs \n",
    "        self.output = np.maximum(0, inputs) \n",
    " \n",
    "    # Backward pass \n",
    "    def backward(self, dvalues): \n",
    "        # Since we need to modify original variable, \n",
    "        # let's make a copy of values first \n",
    "        self.dinputs = dvalues.copy() \n",
    " \n",
    "        # Zero gradient where input values were negative \n",
    "        self.dinputs[self.inputs <= 0] = 0 \n",
    " \n",
    " \n",
    "# Softmax activation \n",
    "class Activation_Softmax: \n",
    " \n",
    "    # Forward pass \n",
    "    def forward(self, inputs): \n",
    "        # Remember input values \n",
    "        self.inputs = inputs \n",
    " \n",
    "        # Get unnormalized probabilities \n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis=1, \n",
    "                                            keepdims=True)) \n",
    "        # Normalize them for each sample \n",
    "        probabilities = exp_values/np.sum(exp_values, axis=1, \n",
    "                                            keepdims=True) \n",
    " \n",
    "        self.output = probabilities \n",
    " \n",
    "    # Backward pass \n",
    "    def backward(self, dvalues): \n",
    " \n",
    "        # Create uninitialized array \n",
    "        self.dinputs = np.empty_like(dvalues) \n",
    " \n",
    "        # Enumerate outputs and gradients \n",
    "        for index, (single_output, single_dvalues) in enumerate(zip(self.output, dvalues)): \n",
    "            # Flatten output array \n",
    "            single_output = single_output.reshape(-1, 1) \n",
    "            # Calculate Jacobian matrix of the output and \n",
    "            jacobian_matrix = np.diagflat(single_output) - np.dot(single_output, single_output.T) \n",
    "            # Calculate sample-wise gradient \n",
    "            # and add it to the array of sample gradients \n",
    "            self.dinputs[index] = np.dot(jacobian_matrix, \n",
    "                                         single_dvalues) \n",
    " \n",
    " \n",
    "# Common loss class \n",
    "class Loss: \n",
    " \n",
    "    # Calculates the data and regularization losses \n",
    "    # given model output and ground truth values \n",
    "    def calculate(self, output, y): \n",
    " \n",
    "        # Calculate sample losses \n",
    "        sample_losses = self.forward(output, y) \n",
    " \n",
    "        # Calculate mean loss \n",
    "        data_loss = np.mean(sample_losses) \n",
    " \n",
    "        # Return loss \n",
    "        return data_loss \n",
    " \n",
    " \n",
    "# Cross-entropy loss \n",
    "class Loss_CategoricalCrossentropy(Loss): \n",
    " \n",
    "    # Forward pass \n",
    "    def forward(self, y_pred, y_true): \n",
    " \n",
    "        # Number of samples in a batch \n",
    "        samples = len(y_pred) \n",
    " \n",
    "        # Clip data to prevent division by 0 \n",
    "        # Clip both sides to not drag mean towards any value \n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7) \n",
    " \n",
    "        # Probabilities for target values - \n",
    "        # only if categorical labels \n",
    "        if len(y_true.shape) == 1: \n",
    "            correct_confidences = y_pred_clipped[ \n",
    "                range(samples), \n",
    "                y_true \n",
    "            ] \n",
    "        # Mask values - only for one-hot encoded labels \n",
    "        elif len(y_true.shape) == 2: \n",
    "            correct_confidences = np.sum( \n",
    "                y_pred_clipped * y_true, \n",
    "                axis=1 \n",
    "            ) \n",
    " \n",
    "        # Losses \n",
    "        negative_log_likelihoods = -np.log(correct_confidences) \n",
    "        return negative_log_likelihoods \n",
    " \n",
    "    # Backward pass \n",
    "    def backward(self, dvalues, y_true): \n",
    " \n",
    "        # Number of samples \n",
    "        samples = len(dvalues) \n",
    "        # Number of labels in every sample \n",
    "        # We'll use the first sample to count them \n",
    "        labels = len(dvalues[0]) \n",
    " \n",
    "        # If labels are sparse, turn them into one-hot vector \n",
    "        if len(y_true.shape) == 1: \n",
    "            y_true = np.eye(labels)[y_true] \n",
    " \n",
    "        # Calculate gradient \n",
    "        self.dinputs = -y_true / dvalues \n",
    "        # Normalize gradient \n",
    "        self.dinputs = self.dinputs/samples \n",
    " \n",
    " \n",
    "# Softmax classifier - combined Softmax activation \n",
    "# and cross-entropy loss for faster backward step \n",
    "class Activation_Softmax_Loss_CategoricalCrossentropy(): \n",
    " \n",
    "    # Creates activation and loss function objects \n",
    "    def __init__(self): \n",
    "        self.activation = Activation_Softmax() \n",
    "        self.loss = Loss_CategoricalCrossentropy() \n",
    " \n",
    "    # Forward pass \n",
    "    def forward(self, inputs, y_true): \n",
    "        # Output layer's activation function \n",
    "        self.activation.forward(inputs) \n",
    "        # Set the output \n",
    "        self.output = self.activation.output \n",
    "        # Calculate and return loss value \n",
    "        return self.loss.calculate(self.output, y_true) \n",
    "    \n",
    "    # Backward pass \n",
    "    def backward(self, dvalues, y_true): \n",
    " \n",
    "        # Number of samples \n",
    "        samples = len(dvalues) \n",
    " \n",
    "        # If labels are one-hot encoded, \n",
    "        # turn them into discrete values \n",
    "        if len(y_true.shape) == 2: \n",
    "            y_true = np.argmax(y_true, axis=1) \n",
    " \n",
    "        # Copy so we can safely modify \n",
    "        self.dinputs = dvalues.copy() \n",
    "        # Calculate gradient \n",
    "        self.dinputs[range(samples), y_true] -= 1 \n",
    "        # Normalize gradient \n",
    "        self.dinputs = self.dinputs/samples \n",
    "\n",
    "#SGD + momentum Optimiser \n",
    "class Optimiser_SGD:\n",
    "\n",
    "    # Initialize optimizer - set settings, \n",
    "    # learning rate of 1. is default for this optimizer\n",
    "    def __init__(self,learning_rate=1.0,decay = 0.,momentum = 0.):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_learning_rate = learning_rate\n",
    "        self.decay = decay\n",
    "        self.iterations = 0\n",
    "        self.momentum = momentum\n",
    "\n",
    "    \"\"\"This method will update the learning rate if decay is anything other than zero\"\"\"\n",
    "    # call once before any updates\n",
    "    def pre_update_params(self):\n",
    "        if self.decay:\n",
    "            self.current_learning_rate = self.learning_rate*(1./(1. + self.decay*self.iterations))\n",
    "    \n",
    "    \"\"\"Major changes are in this method wrt vanilla SGD\"\"\"\n",
    "    #update parameters\n",
    "    def update_params(self,layer):\n",
    "\n",
    "        # if we use momentum\n",
    "        if self.momentum:\n",
    "\n",
    "            # If layer does not contain momentum arrays, create them filled with zeros \n",
    "            if not hasattr(layer, 'weight_momentums'): \n",
    "                layer.weight_momentums = np.zeros_like(layer.weights) \n",
    "                # If there is no momentum array for weights \n",
    "                # The array doesn't exist for biases yet either. \n",
    "                layer.bias_momentums = np.zeros_like(layer.biases)\n",
    "\n",
    "            # Build weight updates with momentum - take previous updates multiplied by retain factor and update with \n",
    "            # current gradients\n",
    "            weight_updates = self.momentum*layer.weight_momentums - self.current_learning_rate*layer.dweights\n",
    "            layer.weight_momentums = weight_updates\n",
    "\n",
    "            # build bias updates\n",
    "            bias_updates = self.momentum*layer.bias_momentums - self.current_learning_rate*layer.biases\n",
    "            layer.bias_momentums = bias_updates\n",
    "\n",
    "        # Vanilla SGD updates (as before momentum update) \n",
    "        else:\n",
    "            weight_updates = -self.current_learning_rate*layer.dweights\n",
    "            bias_updates = -self.current_learning_rate*layer.dbiases\n",
    "\n",
    "        # Update weights and biases using either \n",
    "        # vanilla or momentum updates \n",
    "        layer.weights += weight_updates\n",
    "        layer.biases += bias_updates\n",
    "\n",
    "    # call once after any parameter updates\n",
    "    def post_update_params(self):\n",
    "        self.iterations += 1\n",
    "\n",
    "#AdaGrad Optimiser\n",
    "class Optimiser_Adagrad:\n",
    "\n",
    "    # Initialize optimizer - set settings, \n",
    "    # learning rate of 1. is default for this optimizer\n",
    "    def __init__(self,learning_rate=1.0,decay = 0.,epsilon = 1e-7):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_learning_rate = learning_rate\n",
    "        self.decay = decay\n",
    "        self.iterations = 0\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    \n",
    "    # call once before any updates\n",
    "    def pre_update_params(self):\n",
    "        if self.decay:\n",
    "            self.current_learning_rate = self.learning_rate*(1./(1. + self.decay*self.iterations))\n",
    "    \n",
    "    #update parameters\n",
    "    def update_params(self,layer):\n",
    "\n",
    "        # If layer does not contain cache arrays, create them filled with zeros \n",
    "        if not hasattr(layer, 'weight_cache'): \n",
    "            layer.weight_cache = np.zeros_like(layer.weights)  \n",
    "            layer.bias_cache = np.zeros_like(layer.biases)\n",
    "\n",
    "        # Update cache with squared current gradients \n",
    "        layer.weight_cache += layer.dweights**2 \n",
    "        layer.bias_cache += layer.dbiases**2 \n",
    "\n",
    "        # Vanilla SGD parameter update + normalization \n",
    "        # with square rooted cache \n",
    "        layer.weights += -self.current_learning_rate*layer.dweights/(np.sqrt(layer.weight_cache) +  self.epsilon)\n",
    "        layer.biases += -self.current_learning_rate*layer.dbiases/(np.sqrt(layer.bias_cache) +  self.epsilon)\n",
    "\n",
    "    # call once after any parameter updates\n",
    "    def post_update_params(self):\n",
    "        self.iterations += 1\n",
    "\n",
    "#RMSProp Optimiser\n",
    "class Optimiser_RMSProp:\n",
    "\n",
    "    # Initialize optimizer - set settings, \n",
    "    # learning rate of 1. is default for this optimizer\n",
    "    def __init__(self,learning_rate=0.001,decay = 0.,epsilon = 1e-7,rho = 0.9):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_learning_rate = learning_rate\n",
    "        self.decay = decay\n",
    "        self.iterations = 0\n",
    "        self.epsilon = epsilon\n",
    "        self.rho = rho\n",
    "\n",
    "    \n",
    "    # call once before any updates\n",
    "    def pre_update_params(self):\n",
    "        if self.decay:\n",
    "            self.current_learning_rate = self.learning_rate*(1./(1. + self.decay*self.iterations))\n",
    "    \n",
    "    #update parameters\n",
    "    def update_params(self,layer):\n",
    "\n",
    "        # If layer does not contain cache arrays, create them filled with zeros \n",
    "        if not hasattr(layer, 'weight_cache'): \n",
    "            layer.weight_cache = np.zeros_like(layer.weights)  \n",
    "            layer.bias_cache = np.zeros_like(layer.biases)\n",
    "\n",
    "        # Update cache with squared current gradients \n",
    "        layer.weight_cache += self.rho*layer.weight_cache + (1 - self.rho)*layer.dweights**2 \n",
    "        layer.bias_cache += self.rho*layer.bias_cache + (1 - self.rho)*layer.dbiases**2 \n",
    "\n",
    "        # Vanilla SGD parameter update + normalization \n",
    "        # with square rooted cache \n",
    "        layer.weights += -self.current_learning_rate*layer.dweights/(np.sqrt(layer.weight_cache) +  self.epsilon)\n",
    "        layer.biases += -self.current_learning_rate*layer.dbiases/(np.sqrt(layer.bias_cache) +  self.epsilon)\n",
    "\n",
    "    # call once after any parameter updates\n",
    "    def post_update_params(self):\n",
    "        self.iterations += 1\n",
    "\n",
    "#Adam or Adaptive Momentum Optmiser\n",
    "class Optimiser_Adam: \n",
    " \n",
    "    # Initialize optimizer - set settings \n",
    "    def __init__(self, learning_rate=0.001, decay=0., epsilon=1e-7, \n",
    "                 beta_1=0.9, beta_2=0.999): \n",
    "        self.learning_rate = learning_rate \n",
    "        self.current_learning_rate = learning_rate \n",
    "        self.decay = decay \n",
    "        self.iterations = 0 \n",
    "        self.epsilon = epsilon \n",
    "        self.beta_1 = beta_1 \n",
    "        self.beta_2 = beta_2 \n",
    " \n",
    "    # Call once before any parameter updates \n",
    "    def pre_update_params(self): \n",
    "        if self.decay: \n",
    "            self.current_learning_rate = self.learning_rate*(1. / (1. + self.decay * self.iterations)) \n",
    " \n",
    "    # Update parameters \n",
    "    def update_params(self, layer): \n",
    " \n",
    "        # If layer does not contain cache arrays, \n",
    "        # create them filled with zeros \n",
    "        if not hasattr(layer, 'weight_cache'): \n",
    "            layer.weight_momentums = np.zeros_like(layer.weights) \n",
    "            layer.weight_cache = np.zeros_like(layer.weights) \n",
    "            layer.bias_momentums = np.zeros_like(layer.biases) \n",
    "            layer.bias_cache = np.zeros_like(layer.biases) \n",
    " \n",
    "        # Update momentum  with current gradients \n",
    "        layer.weight_momentums = self.beta_1*layer.weight_momentums + (1 - self.beta_1)*layer.dweights \n",
    "        layer.bias_momentums = self.beta_1*layer.bias_momentums + (1 - self.beta_1)*layer.dbiases \n",
    "\n",
    "        # Get corrected momentum \n",
    "        # self.iteration is 0 at first pass \n",
    "        # and we need to start with 1 here \n",
    "        weight_momentums_corrected = layer.weight_momentums/(1 - self.beta_1 ** (self.iterations + 1)) \n",
    "        bias_momentums_corrected = layer.bias_momentums/(1 - self.beta_1 ** (self.iterations + 1)) \n",
    "\n",
    "        # Update cache with squared current gradients \n",
    "        layer.weight_cache = self.beta_2 * layer.weight_cache + (1 - self.beta_2) * layer.dweights**2 \n",
    "        layer.bias_cache = self.beta_2 * layer.bias_cache + (1 - self.beta_2) * layer.dbiases**2 \n",
    "\n",
    "        # Get corrected cache \n",
    "        weight_cache_corrected = layer.weight_cache/(1 - self.beta_2 ** (self.iterations + 1)) \n",
    "        bias_cache_corrected = layer.bias_cache/(1 - self.beta_2 ** (self.iterations + 1)) \n",
    " \n",
    "        # Vanilla SGD parameter update + normalization \n",
    "        # with square rooted cache \n",
    "        layer.weights += -self.current_learning_rate*weight_momentums_corrected/(np.sqrt(weight_cache_corrected) + self.epsilon) \n",
    "        layer.biases += -self.current_learning_rate*bias_momentums_corrected/(np.sqrt(bias_cache_corrected) + self.epsilon) \n",
    " \n",
    "    # Call once after any parameter updates \n",
    "    def post_update_params(self): \n",
    "        self.iterations += 1\n",
    " \n",
    "# Create dataset \n",
    "X, y = spiral_data(samples=100, classes=3) \n",
    " \n",
    "# Create Dense layer with 2 input features and 64 output values \n",
    "dense1 = Layer_Dense(2, 64) \n",
    " \n",
    "# Create ReLU activation (to be used with Dense layer): \n",
    "activation1 = Activation_ReLU() \n",
    " \n",
    "# Create second Dense layer with 64 input features (as we take output \n",
    "# of previous layer here) and 3 output values (output values) \n",
    "dense2 = Layer_Dense(64, 3) \n",
    " \n",
    "# Create Softmax classifier's combined loss and activation \n",
    "loss_activation = Activation_Softmax_Loss_CategoricalCrossentropy() \n",
    " \n",
    "# Create optimizer \n",
    "#optimiser = Optimiser_SGD(decay=8e-8, momentum=0.9)\n",
    "\n",
    "optimiser = Optimiser_Adam(learning_rate=0.05,decay=5e-7) \n",
    "# Train in loop \n",
    "for epoch in range(10001): \n",
    " \n",
    "    # Perform a forward pass of our training data through this layer \n",
    "    dense1.forward(X) \n",
    " \n",
    "    # Perform a forward pass through activation function \n",
    "    # takes the output of first dense layer here \n",
    "    activation1.forward(dense1.output) \n",
    " \n",
    "    # Perform a forward pass through second Dense layer \n",
    "    # takes outputs of activation function of first layer as inputs \n",
    "    dense2.forward(activation1.output) \n",
    " \n",
    "    # Perform a forward pass through the activation/loss function \n",
    "    # takes the output of second dense layer here and returns loss \n",
    "    loss = loss_activation.forward(dense2.output, y) \n",
    " \n",
    "    # Calculate accuracy from output of activation2 and targets \n",
    "    # calculate values along first axis \n",
    "    predictions = np.argmax(loss_activation.output, axis=1) \n",
    "    if len(y.shape) == 2: \n",
    "        y = np.argmax(y, axis=1) \n",
    "    accuracy = np.mean(predictions==y) \n",
    " \n",
    "    if not epoch % 100: \n",
    "        print(f'epoch: {epoch}, ' + \n",
    "              f'acc: {accuracy:.3f}, ' + \n",
    "              f'loss: {loss:.3f}, ' + \n",
    "              f'lr: {optimiser.current_learning_rate}') \n",
    " \n",
    "    # Backward pass \n",
    "    loss_activation.backward(loss_activation.output, y) \n",
    "    dense2.backward(loss_activation.dinputs) \n",
    "    activation1.backward(dense2.dinputs) \n",
    "    dense1.backward(activation1.dinputs) \n",
    " \n",
    "    # Update weights and biases \n",
    "    optimiser.pre_update_params() \n",
    "    optimiser.update_params(dense1) \n",
    "    optimiser.update_params(dense2) \n",
    "    optimiser.post_update_params()\n",
    "\n",
    "# Validate the model \n",
    "\n",
    "# Create test dataset \n",
    "X_test, y_test = spiral_data(samples=100, classes=3) \n",
    "# Perform a forward pass of our testing data through this layer \n",
    "dense1.forward(X_test) \n",
    "# Perform a forward pass through activation function \n",
    "# takes the output of first dense layer here \n",
    "activation1.forward(dense1.output) \n",
    "# Perform a forward pass through second Dense layer \n",
    "# takes outputs of activation function of first layer as inputs \n",
    "dense2.forward(activation1.output) \n",
    "# Perform a forward pass through the activation/loss function \n",
    "# takes the output of second dense layer here and returns loss \n",
    "loss = loss_activation.forward(dense2.output, y_test) \n",
    "# Calculate accuracy from output of activation2 and targets \n",
    "# calculate values along first axis \n",
    "predictions = np.argmax(loss_activation.output, axis=1) \n",
    "if len(y_test.shape) == 2: \n",
    "    y_test = np.argmax(y_test, axis=1) \n",
    "accuracy = np.mean(predictions==y_test) \n",
    "print(f'validation, acc: {accuracy:.3f}, loss: {loss:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While 79.7% accuracy and a loss of 0.921​ is not terrible, this contrasts with our training data \n",
    "that achieved 97% accuracy and a loss of 0.074. This is evidence of over-fitting. <br><br>\n",
    "![](img2.png) <br><br>\n",
    "\n",
    "- We can recognize overfitting when testing data results begin to diverge in trend from training data. \n",
    "- It will usually be the case that performance against your training data is better, but having training loss differ from test performance by over 10% approximately is a common sign of serious overfitting from our anecdotal experience. Ideally, both datasets would have identical performance. \n",
    "- Even a small difference means that the model did not correctly predict some testing samples, implying slight overfitting of training data. In most cases, modest overfitting is not a serious problem, but something we hope to minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is a classic example of overfitting — the validation loss falls down, then starts rising once \n",
    "the model starts overfitting. \n",
    "- The model is currently tuned to achieve the best possible score on the training data, and most likely the learning rate is too high, there are too many training epochs, or the model is too big. There are other possible causes and ways to fix this.\n",
    "- In general, the goal is to have the testing loss identical to the training loss, even if that means higher loss and lower accuracy on the training data. Similar performance on both datasets means that model generalized instead of overfitting on the training data.\n",
    "- One general rule to follow when selecting initial model hyperparameters is to find the smallest model possible that still learns.\n",
    "- Other possible ways to avoid overfitting are regularization techniques, and the Dropout​ layer. \n",
    "- The process of trying different model settings is called **hyperparameter searching**. Initially, you can very quickly (usually within minutes) try different settings (e.g., layer sizes) to see if the models are learning something​. If they are, train the models fully — or at least significantly longer — and compare results to pick the best set of hyperparameters. \n",
    "- Another possibility is to create a list of different hyperparameter sets and train the model in a loop using each of those sets at a time to pick the best set at the end. \n",
    "- The reasoning here is that the fewer neurons you have, the less chance you have that the model is memorizing the data. Fewer neurons can mean it’s easier for a neural network to generalize (actually learn the meaning of the data) compared to memorizing the data. \n",
    "- With enough neurons, it’s easier for a neural network to memorize the data. Remember that the neural network wants to decrease training loss and follows the path of least resistance to meet that objective. Our job as the programmer is to make the path to generalization the easiest path. This can often mean our job is actually to make the path to lowering loss for the model more \n",
    "challenging!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
